OLLAMA_HOST="localhost"
OLLAMA_PORT=50051

# Pipeline Configuration
CHUNK_SIZE=2000
MAX_TOKENS=2000
OVERLAP_SENTENCES=20
MODEL_NAME=llama3.2:3b
MAX_WORKERS=4